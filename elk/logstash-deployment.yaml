apiVersion: v1
kind: ConfigMap
metadata:
  name: logstash-configmap
  namespace: logging
data:
  logstash.yml: |
    http.host: "0.0.0.0"
    path.config: /usr/share/logstash/pipeline
  logstash.conf: |
    input {
      beats {
        port => "5044"
      }
    }
    
    filter {
      if [type] == "jenkins-server" {
      # set all messages from the jenkins log as type 'jenkins' and add the @message field.
          mutate {
              add_field => ["@message_type", "jenkins"]
              add_field => ["@message", "%{message}"]
          }
        }
      }
    # now that we have possibly-multiline events, we can clean them up.
    filter {
    # munge the possibly-multiline messages into a single string
        mutate {
          join => ["@message", "\n"]
        }
    # split @message into __date and __msg, and overwrite the @timestamp value.
      grok {
          match => [ "@message", "^(?<__date>%{MONTH} %{MONTHDAY}, %{YEAR} %{TIME} (AM|PM)) (?<__msg>.+)" ]
      }
      date {
          match  => [ "__date", "MMM dd, YYYY HH:mm:ss a"]
      }
    # ...now some patterns to categorize specific event types...
    # parse build completion messages, adding the jenkins_* fields and the 'build' tag
      grok {
          match => [ "@message", "(?<jenkins_job>\S+) #(?<jenkins_build_number>\d+) (?<__msg>.+): (?<jenkins_build_status>\w+)" ]
          tag_on_failure => []
          overwrite => true
          add_tag => ['build']
      }
       
    # convert build number from string to integer
      mutate {
        convert => ["jenkins_build_number", "integer"]
      }
    # tag messages that come from the perforce SCM plugin (and associated classes)
      grok {
        match => [ "@message", "\.perforce\."]
        tag_on_failure => []
        add_tag => ['p4-plugin']
      }
    # if we have extracted a short message string, replace @message with it now
      if [__msg] {
        mutate {
          replace => ["@message","%{__msg}"]
        }
      }
    # convert @message back into an array of lines
        mutate {
          split => ["@message", "\n"]
        }
    }
    # clean-up temporary fields and unwanted tags.
    filter {
      mutate {
        remove_field => [
          "message",
          "__msg",
          "__date",
          "dumps1",
          "plugin_command"
        ]
        remove_tag => [
          "multiline",
          "_grokparsefailure"
        ]
      }
    }
    # send it on to the elasticsearch
    output {
      elasticsearch {
        hosts =>   ["10.104.225.11:9200"]               #["192.168.49.2:30920"]                                   #
    
    # username & password to connect to elaticsearch
        user => "elastic"
        password =>  "changeme"         #"elastic"
    
        action => "index"
        index => "jenkins-%{+YYYY.MM.dd}"}
 
    # use this if you want to verify logs are being sent to elasticsearch or not
 
    #stdout { codec => rubydebug }
    }
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: logstash-deployment
  namespace: logging
spec:
  replicas: 1
  selector:
    matchLabels:
      app: logstash
  template:
    metadata:
      labels:
        app: logstash
    spec:
      containers:
      - name: logstash
        image: docker.elastic.co/logstash/logstash:7.16.2
        ports:
        - containerPort: 5044
        volumeMounts:
          - name: config-volume
            mountPath: /usr/share/logstash/config
          - name: logstash-pipeline-volume
            mountPath: /usr/share/logstash/pipeline
      volumes:
      - name: config-volume
        configMap:
          name: logstash-configmap
          items:
            - key: logstash.yml
              path: logstash.yml
      - name: logstash-pipeline-volume
        configMap:
          name: logstash-configmap
          items:
            - key: logstash.conf
              path: logstash.conf
---
kind: Service
apiVersion: v1
metadata:
  name: logstash-service
  namespace: logging
spec:
  selector:
    app: logstash
  ports:
  - protocol: TCP
    port: 5044
    targetPort: 5044
  type: ClusterIP
